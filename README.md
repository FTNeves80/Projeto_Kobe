# Projeto kobe

# Link para o reposit√≥rio: https://github.com/FTNeves80/Projeto_Kobe


## Overview

This is your new Kedro project, which was generated using `kedro 0.19.12`.

exemplo de sintaxe de MD [Kedro documentation](https://docs.kedro.org) to get started.

### JupyterLab
## Project dependencies


```
Exmplo de marca√ßao MD kedro jupyter notebook
```

### IPython
And if you want to run an IPython session:

## Diagrama do projeto
![Diagrama](data/08_reporting/Diagrama.png)


Analisando a tabela, vamos comparar os principais indicadores de desempenho entre os modelos lr (Logistic Regression) e dt (Decision Tree):

M√©trica	Logistic Regression (lr)	Decision Tree (dt)	Melhor
AUC	0.5921	0.5923	Empate (quase id√™nticos)
Accuracy	0.5682	0.5883	dt
F1 Score	0.5397	0.4644	lr
Recall	0.5296	0.3758	lr
Log Loss	0.6821	0.7171	lr (menor √© melhor)
üß† An√°lise
F1 Score e Recall s√£o m√©tricas muito importantes quando o dataset √© desbalanceado ou voc√™ quer equilibrar falsos positivos e falsos negativos.

Log Loss penaliza muito previs√µes com alta confian√ßa e erradas ‚Äî e o lr tamb√©m teve melhor resultado aqui.

A AUC praticamente empatou, com vantagem min√∫scula para a √°rvore.

A Accuracy foi maior na dt, mas isso pode ser enganoso em problemas com desequil√≠brio nas classes.

‚úÖ Conclus√£o
Voc√™ deve escolher o Logistic Regression (lr), porque:

Ele teve melhor F1, melhor Recall, menor Log Loss.

A pequena perda em Accuracy e AUC n√£o compensa a perda nos outros pontos, principalmente se seu problema √© sens√≠vel a erros de classifica√ß√£o.

Se quiser, posso te ajudar a registrar isso no MLflow ou usar como base para uma pr√≥xima infer√™ncia!
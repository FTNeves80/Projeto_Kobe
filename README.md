# Projeto kobe

### Link para o reposit√≥rio: https://github.com/FTNeves80/Projeto_Kobe

## 1.Diagrama do projeto
![Diagrama](docs/Diagrama.png)

### 2. Como as ferramentas Streamlit, MLFlow, PyCaret e Scikit-Learn auxiliam na constru√ß√£o dos pipelines descritos anteriormente? A resposta deve abranger os seguintes aspectos:
   #### 2.1 Rastreamento de experimentos:
    Com o MLFlow √© poss√≠vel registrar as m√©tricas, artefatos e par√¢metros de forma autom√°tica. O MLFlow possui uma interface onde voc√™ pode consultas e comparar todas as informa√ß√µes registradas tanto atuais como historicamente. Ele cria uma espece de central de informa√ß√µes muito √∫til para a utiliza√ß√£o de controle e registro do ciclo de desenvolvimento dos modelos.
                
   #### 2.2 Fun√ß√µes de treinamento:
    O Scikit-Learn √© uma biblioteca poderosa e bastante utilizada no mercado, com uma grande variedade de algoritmos para treinamento de modelos. J√° o PyCaret ajuda a automatizar esse processo, permitindo treinar diversos modelos, comparar resultados e ajustar hiperpar√¢metros com poucas linhas de c√≥digo. Isso economiza tempo e facilita a obten√ß√£o de bons resultados de forma mais eficiente.
                
   #### 2.3 Monitoramento da sa√∫de do modelo:
    O monitoramento da sa√∫de do modelo pode ser feito registrando periodicamente as m√©tricas de performance no MLflow, como AUC, F1-score, Log Loss, entre outras. Isso ajuda a perceber se o modelo est√° piorando com o tempo (drift de dados ou de conceito). Com isso, conseguimos identificar quando √© hora de reavaliar ou atualizar o modelo. Ferramentas como o PyCaret facilitam essa parte, pois permitem reusar facilmente o pipeline de treino e avalia√ß√£o para comparar com vers√µes anteriores.
    
   #### 2.4 Atualiza√ß√£o de modelo:
    Utilizando PyCaret e MLflow, a atualiza√ß√£o de um modelo pode ser feita de forma automatizada. √â poss√≠vel configurar um pipeline para retreinar o modelo com dados mais recentes ou com novos par√¢metros, registrando uma nova vers√£o no MLflow. A partir da√≠, voc√™ pode promover essa nova vers√£o para produ√ß√£o, mantendo o hist√≥rico e comparando com vers√µes anteriores.
                
   #### 2.5 Provisionamento (Deployment).
    O MLflow permite que voc√™ sirva o modelo em um servidor, gerando uma API que recebe inputs e retorna previs√µes. J√° o Streamlit pode ser usado para construir uma interface gr√°fica (front-end) que consome essa API, permitindo a visualiza√ß√£o e intera√ß√£o com o modelo de forma simples e intuitiva.

### 4 Com base no diagrama realizado na quest√£o 2, aponte os artefatos que ser√£o criados ao longo de um projeto. Para cada artefato, a descri√ß√£o detalhada de sua composi√ß√£o.
![Diagrama_artefatos](docs/Diagrama_artefatos.png)
![Diagrama_artefatos](docs/Diagrama_artefatos2.png)


## Overview

This is your new Kedro project, which was generated using `kedro 0.19.12`.

exemplo de sintaxe de MD [Kedro documentation](https://docs.kedro.org) to get started.

### JupyterLab
## Project dependencies


```
Exmplo de marca√ßao MD kedro jupyter notebook
```

### Como executar o projeto Ajudar essa respostas
1-kedro run
2-subir o modelo
3-moninotar via mlflow
4-Visualizar o front-end


Analisando a tabela, vamos comparar os principais indicadores de desempenho entre os modelos lr (Logistic Regression) e dt (Decision Tree):

M√©trica	Logistic Regression (lr)	Decision Tree (dt)	Melhor
AUC	0.5921	0.5923	Empate (quase id√™nticos)
Accuracy	0.5682	0.5883	dt
F1 Score	0.5397	0.4644	lr
Recall	0.5296	0.3758	lr
Log Loss	0.6821	0.7171	lr (menor √© melhor)
üß† An√°lise
F1 Score e Recall s√£o m√©tricas muito importantes quando o dataset √© desbalanceado ou voc√™ quer equilibrar falsos positivos e falsos negativos.

Log Loss penaliza muito previs√µes com alta confian√ßa e erradas ‚Äî e o lr tamb√©m teve melhor resultado aqui.

A AUC praticamente empatou, com vantagem min√∫scula para a √°rvore.

A Accuracy foi maior na dt, mas isso pode ser enganoso em problemas com desequil√≠brio nas classes.

‚úÖ Conclus√£o
Voc√™ deve escolher o Logistic Regression (lr), porque:

Ele teve melhor F1, melhor Recall, menor Log Loss.

A pequena perda em Accuracy e AUC n√£o compensa a perda nos outros pontos, principalmente se seu problema √© sens√≠vel a erros de classifica√ß√£o.

Se quiser, posso te ajudar a registrar isso no MLflow ou usar como base para uma pr√≥xima infer√™ncia!